# Example configuration for Eyes - macOS System Observer
# All fields are optional - defaults are provided for missing values

[logging]
# Predicate filter for log stream (Apple's query language)
predicate = "messageType == error OR messageType == fault"

[metrics]
# Interval between metrics samples (in seconds)
interval_seconds = 5

[buffer]
# Maximum age of events in the rolling buffer (in seconds)
max_age_seconds = 60
# Maximum number of events in the rolling buffer
max_size = 1000

[triggers]
# Number of errors required to trigger AI analysis
error_threshold = 5
# Time window for error counting (in seconds)
error_window_seconds = 10
# Memory pressure level that triggers AI analysis ("Normal", "Warning", "Critical")
memory_threshold = "Warning"

[alerts]
# Maximum number of alerts per minute
rate_limit_per_minute = 3

# AI Backend Configuration
# Choose one of the following backend configurations:

# Option 1: Ollama (Local LLM - Recommended for privacy)
[ai]
backend = "ollama"
endpoint = "http://localhost:11434"
model = "llama3"

# Option 2: OpenAI (Cloud-based)
# [ai]
# backend = "openai"
# api_key = "sk-your-api-key-here"
# model = "gpt-4"

# Option 3: Mock (Testing and development)
# [ai]
# backend = "mock"